name: Build

on:
  schedule:
    - cron: "0 0 * * *" # Triggers the workflow to run once a day at midnight UTC.
  push:
    branches:
      - dev
      - main
      - release-*
      - feat-*
      - ci-*
      - refactor-*
      - fix-*
      - test-*
    paths:
      - '.github/workflows/**'
      - '**/Cargo.toml'
      - '**/*.rs'
      - '**/*.sh'
  pull_request:
    branches:
      - dev
      - main
    types: [opened, synchronize, reopened]
    paths:
      - '.github/workflows/**'
      - '**/Cargo.toml'
      - '**/*.rs'
      - '**/*.sh'

jobs:
  build-wasm:
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ubuntu-22.04, ubuntu-20.04, macos-12, macos-13]
    steps:
      - name: Clone project
        id: checkout
        uses: actions/checkout@v3

      - name: Install Rust-nightly
        uses: actions-rust-lang/setup-rust-toolchain@v1
        with:
          toolchain: nightly
          target: wasm32-wasi
          components: rustfmt, clippy

      - name: Install Rust-stable
        uses: actions-rust-lang/setup-rust-toolchain@v1
        with:
          target: wasm32-wasi

      - name: Install WasmEdge
        run: |
          curl -sSf https://raw.githubusercontent.com/WasmEdge/WasmEdge/master/utils/install_v2.sh | bash -s -- -v 0.13.5
          source $HOME/bash.rc
          wasmedge --version

      - name: Build simple
        id: build_simple
        run: |
          cd simple
          cargo +nightly fmt --all -- --check
          cargo +nightly clippy --target wasm32-wasi -- -D warnings
          cargo build --target wasm32-wasi --release

      - name: Build chat
        id: build_chat
        run: |
          cd chat
          cargo +nightly fmt --all -- --check
          cargo +nightly clippy --target wasm32-wasi -- -D warnings
          cargo build --target wasm32-wasi --release

      - name: Build api-server
        id: build_api_server
        run: |
          cd api-server
          cargo +nightly fmt --all -- --check
          cargo +nightly clippy --target wasm32-wasi -- -D warnings
          cargo build --target wasm32-wasi --release
          cp target/wasm32-wasi/release/llama-api-server.wasm .

      - name: start api-server
        continue-on-error: true
        if : ${{ matrix.os == 'ubuntu-22.04' }}
        run: |
          cd api-server
          curl -LO https://huggingface.co/second-state/Qwen2-0.5B-Instruct-GGUF/resolve/main/Qwen2-0.5B-Instruct-Q5_K_M.gguf
          nohup wasmedge --dir .:. --nn-preload default:GGML:AUTO:Qwen2-0.5B-Instruct-Q5_K_M.gguf llama-api-server.wasm --model-name Qwen2-0.5B-Instruct --prompt-template chatml --ctx-size 32000 &

      - name: Test localhost API
        continue-on-error: true
        if: ${{ matrix.os == 'ubuntu-22.04' }}
        run: |
          curl --fail -X POST http://localhost:8080/v1/chat/completions \
            -H 'accept: application/json' \
            -H 'Content-Type: application/json' \
            -d '{"messages":[{"role":"system", "content": "You are a helpful assistant."}, {"role":"user", "content": "What is the capital of France?"}], "model":"Qwen2-0.5B-Instruct"}'

      - name: Build api-server-full
        id: build_api_server_full
        run: |
          cd api-server
          cargo +nightly fmt --all -- --check
          cargo +nightly clippy --target wasm32-wasi --features full -- -D warnings
          cargo build --target wasm32-wasi --release --features full
